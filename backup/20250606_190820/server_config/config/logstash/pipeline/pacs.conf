input {
  # Collect logs from files
  file {
    path => "/logs/nginx/*.log"
    start_position => "beginning"
    tags => ["nginx"]
    codec => plain {
      charset => "UTF-8"
    }
  }
  
  file {
    path => "/logs/orthanc/*.log"
    start_position => "beginning"
    tags => ["orthanc"]
    codec => plain {
      charset => "UTF-8"
    }
  }
  
  file {
    path => "/logs/flask_auth/*.log"
    start_position => "beginning"
    tags => ["flask_auth"]
    codec => plain {
      charset => "UTF-8"
    }
  }
  
  file {
    path => "/logs/postgres/*.log"
    start_position => "beginning"
    tags => ["postgres"]
    codec => plain {
      charset => "UTF-8"
    }
  }
  
  # Collect Docker logs via TCP
  tcp {
    port => 5000
    codec => json
    tags => ["docker"]
  }
}

filter {
  # Parse nginx access logs
  if "nginx" in [tags] and "access" in [path] {
    grok {
      match => {
        "message" => '%{IPORHOST:client_ip} - %{DATA:user} \[%{HTTPDATE:timestamp}\] "%{WORD:method} %{DATA:request} HTTP/%{NUMBER:http_version}" %{NUMBER:status} %{NUMBER:bytes} "%{DATA:referrer}" "%{DATA:user_agent}"'
      }
    }
    
    date {
      match => [ "timestamp", "dd/MMM/yyyy:HH:mm:ss Z" ]
    }
    
    # Add geolocation
    geoip {
      source => "client_ip"
      target => "geoip"
    }
    
    # Parse user agent
    useragent {
      source => "user_agent"
      target => "ua"
    }
  }
  
  # Parse Flask auth logs (JSON format)
  if "flask_auth" in [tags] {
    json {
      source => "message"
    }
    
    # Extract user actions
    if [action] {
      mutate {
        add_field => {
          "audit_action" => "%{action}"
          "audit_user" => "%{username}"
          "audit_resource" => "%{resource_type}/%{resource_id}"
        }
      }
    }
  }
  
  # Parse Orthanc logs
  if "orthanc" in [tags] {
    grok {
      match => {
        "message" => "%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:level} %{GREEDYDATA:orthanc_message}"
      }
    }
    
    # Extract DICOM operations
    if [orthanc_message] =~ /DICOM/ {
      mutate {
        add_tag => [ "dicom_operation" ]
      }
    }
  }
  
  # Parse PostgreSQL logs
  if "postgres" in [tags] {
    grok {
      match => {
        "message" => "%{TIMESTAMP_ISO8601:timestamp} \[%{NUMBER:pid}\] %{LOGLEVEL:level}: %{GREEDYDATA:pg_message}"
      }
    }
  }
  
  # Add common fields
  mutate {
    add_field => {
      "environment" => "${ENVIRONMENT:production}"
      "service" => "pacs"
    }
    
    # Remove sensitive data
    remove_field => [ "password", "token", "jwt", "secret" ]
  }
  
  # Track authentication events
  if [path] =~ /auth/ or [action] =~ /login|logout/ {
    mutate {
      add_tag => [ "authentication" ]
    }
  }
  
  # Track medical data access
  if [action] =~ /view_study|view_patient|export_report/ {
    mutate {
      add_tag => [ "phi_access" ]
    }
  }
}

output {
  # Send to Elasticsearch
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "pacs-logs-%{+YYYY.MM.dd}"
    template_name => "pacs-logs"
    template => "/usr/share/logstash/templates/pacs-template.json"
    template_overwrite => true
  }
  
  # Alert on critical events
  if "authentication" in [tags] and [status] >= 400 {
    email {
      to => "${ALERT_EMAIL:admin@klinika-pro.ru}"
      subject => "PACS Authentication Failure Alert"
      body => "Failed authentication attempt:\nUser: %{username}\nIP: %{client_ip}\nTime: %{@timestamp}\nStatus: %{status}"
    }
  }
  
  # Console output for debugging
  if "${DEBUG:false}" == "true" {
    stdout {
      codec => rubydebug
    }
  }
} 